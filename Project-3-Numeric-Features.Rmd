---
title: "Project 3 numeric features"
author: "Tejit Pabari"
date: "4/16/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	class.source="bg-success",
	class.output="bg-warning"
)

library(ggplot2)
library(scales)
library(glmnet)
library(jsonlite)
library(superml)
library(tidytext)
library(text2vec)
library(dplyr)
library(forcats)
library(stopwords)
library(clue)
library(cluster)
library(factoextra)
library(readtext)
library(tokenizers)
library(pdist)
library(readr)
library(stringr)
library(ape)
library(dbscan)
library(randomForest)
library(vader)
setwd("/Users/tejitpabari/Desktop/DataMining/Projects/3")
gg_global_theme <- theme(axis.text=element_text(size=16))
set.seed(8)
# rm(list = ls())
```

## Load data
```{r}
genius_data <- read_csv("data/genuis_data.csv")
info_cols <- c("key", "song", "artist", "album_name")
ranking_cols <- sapply((2006:2020), function(x) paste0("song_ranking_",x))
feature_cols <- names(genius_data)[13:23]
feature_cols2 <- c(feature_cols,"song_popularity", "song_duration", "song_lyric_valence", "song_lyrics_repetitiveness")
feature_cols_album <- c(feature_cols2,"album_total_tracks","album_popularity")
genius_data$max_ranking <- apply(genius_data[,ranking_cols], 1, max)
genius_data$max_ranking_year <- sapply(ranking_cols[apply(genius_data[,ranking_cols], 1, which.max)], function(x) as.numeric(strsplit(x,"_")[[1]][3]))
genius_data$ranking_duration <- apply(genius_data[,ranking_cols], 1, function(x) length(x[x!=0]))
ranking_info_cols = c("max_ranking","max_ranking_year","ranking_duration")
exclude_cols = c("kmeans", "kmeans2","kmeans_album","clus","max_ranking","ranking_3")

genius_data$ranking_3 <- sapply(genius_data$max_ranking, function(x){
  if(x<=10){return(1)}
  if(x<=50){return(2)}
  return(3)
})
```


### Functions
```{r}
fname <- function(x) return(str_replace(x,"_"," "))
run_lm_features <- function(df, y="max_ranking", exclude_cols=NULL, color=NULL,
                            save_pre=NULL, plot=TRUE){
  feature_names <- names(df)[!(names(df) %in% c(exclude_cols,color,y))]
  yn <- fname(y)
  for(f in feature_names){
    xn <- fname(f)
    fig = ggplot(df, aes_string(f, y, color=color)) + geom_point() + 
      ggtitle(paste0(yn," and ",xn)) + xlab(xn) + ylab(yn)
    if (plot==TRUE) print(fig)
    if (!is.null(save_pre)){
      filename <- paste0(y,"_",f)
      ggsave(file.path(save_pre,filename))
    }
  }
}
```

## Data Preprocessing
```{r}
preprocess_func_base <- function (org_text){
  text <- tolower(org_text)
  return(text)
}
preprocess_func_2 <- function (org_text) {
  text <- replace_contraction(org_text)
  text <- gsub("[^[:alpha:][:space:]]", "", text)
  text <- gsub("\\s+", " ", text)
  text <- preprocess_func_base(text)
  return(text)
}
example_text <- genius_data$song_lyrics[1]
preprocess_func_2(example_text)
```

### Processing Data
```{r}
genius_data$song_lyrics_pre <- unname(sapply(genius_data$song_lyrics, function(x) preprocess_func_2(x)))
```


### valence and repeat
```{r}
# get_comp_sent <- function(val) as.numeric(unname(get_vader(val)[2]))
# genius_data$song_lyric_valence <- unname(sapply(genius_data$song_lyrics_pre, get_comp_sent))
# 
# get_song_repeat <- function(txt) {
#   words <- strsplit(txt," ")[[1]]
#   return(1-length(unique(words))/length(words))
# }
# genius_data$song_lyrics_repetitiveness <- unname(sapply(genius_data$song_lyrics_pre, get_song_repeat))
```

```{r}
# write.csv(genius_data, "data/genuis_data.csv",row.names = FALSE)
```

### Train test split 
Train test split based on max_ranking3, for all columns
```{r}
test_split = 0.2
test_data_inds <- unlist(sapply(1:3, function(x) {
  inds <- which(genius_data$ranking_3==x)
  inds_test = round(test_split*length(inds))
  return(sample(inds, inds_test))
}))
test_data <- genius_data[test_data_inds,]
train_data <- genius_data[-test_data_inds,]
```

```{r}
# Feature Cols
feature_cols_data <- genius_data[,feature_cols]
feature_cols_data_rank <- genius_data[,c(feature_cols, "max_ranking")]
feature_cols_data_rank3 <- genius_data[,c(feature_cols, "ranking_3")]
# Feature cols 2
feature_cols2_data <- scale(genius_data[,feature_cols2])
# feature_cols2_data_rank <- genius_data[,c(feature_cols2, "max_ranking")]
feature_cols2_data_rank3 <- cbind(feature_cols2_data,genius_data$ranking_3)
colnames(feature_cols2_data_rank3) <- c(head(colnames(feature_cols2_data_rank3),-1),"ranking_3")
feature_cols2_data <- as.data.frame(feature_cols2_data)
feature_cols2_data_rank3 <- as.data.frame(feature_cols2_data_rank3)
# Feature cols 2 + album info
feature_cols_album_data <- genius_data[,feature_cols_album]
feature_cols_album_data_rank <- genius_data[,c(feature_cols_album, "max_ranking")]
feature_cols_album_data_rank3 <- genius_data[,c(feature_cols_album, "ranking_3")]
```

### Train test split 
Train test split based on max_ranking3, for all columns
```{r}
test_split = 0.2
test_data_inds <- unlist(sapply(1:3, function(x) {
  inds <- which(feature_cols2_data_rank3$ranking_3==x)
  inds_test = round(test_split*length(inds))
  return(sample(inds, inds_test))
}))
test_data <- feature_cols2_data_rank3[test_data_inds,]
train_data <- feature_cols2_data_rank3[-test_data_inds,]
```


## Regression
### Regression with song popularity
#### Max Ranking
```{r}
ols <- lm(max_ranking~song_popularity, genius_data)
ggplot(feature_cols2_data_rank, aes(x = song_popularity, y = max_ranking)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Max Ranking of Song") + xlab("Song popularity") +
  ggtitle("Max Ranking vs Song popularity")
```
Popularity doesn't have a relation with rankings. Spotify popularity calculates how popular the song is based on recent plays. It is calculated by number of plays in a short amount of time. Billboard is yearend and includes plays, album sales, radio plays etc.
https://help.musicinsights.com/hc/en-us/articles/360049246653-What-is-the-Spotify-Popularity-Score-#:~:text=The%20score%20is%20received%20from,how%20recent%20those%20plays%20are.

#### Ranking 3
```{r}
ggplot(feature_cols2_data_rank3, aes(x = song_popularity, y = ranking_3)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Ranking 3 of Song") + xlab("Song popularity") +
  ggtitle("Ranking 3 vs Song popularity")
```

### Regression with song tempo
```{r}
ggplot(feature_cols2_data_rank3, aes(x = song_tempo, y = ranking_3)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Ranking 3 of Song") + xlab("Song tempo") +
  ggtitle("Ranking 3 vs Song tempo")
```


### Regression with song valence
```{r}
ggplot(feature_cols2_data_rank3, aes(x = song_lyric_valence, y = ranking_3)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Ranking 3 of Song") + xlab("Song lyrics valence") +
  ggtitle("Ranking 3 vs Song lyric valence")
```

### Regression with song repeat
```{r}
ggplot(feature_cols2_data_rank3, aes(x = song_lyrics_repetitiveness, y = ranking_3)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Ranking 3 of Song") + xlab("Song lyrics repeat") +
  ggtitle("Ranking 3 vs Song lyric repeat")
```

### Regression b/w song valence and lyric valence
```{r}
ols <- lm(song_lyric_valence~song_valence, genius_data)
ggplot(genius_data, aes(x = song_lyric_valence, y = song_valence)) +
  geom_point() + 
  geom_smooth(method='lm', formula=y~x, col='red', se=FALSE) + 
  ylab("Song Valence") + xlab("Song lyric Valence") +
  ggtitle("Song Valence vs Song lyric valence")
```



### Regression with feature cols
#### Max Ranking
```{r}
# feature cols
ols <- lm(max_ranking ~ ., feature_cols_data_rank)
summary(ols)

# feature cols 2
ols <- lm(max_ranking ~ ., feature_cols2_data_rank)
summary(ols)

# feature cols 2 + album
ols <- lm(max_ranking ~ ., feature_cols_album_data_rank)
summary(ols)
```

#### Ranking 3
```{r}
# feature cols
ols <- lm(ranking_3 ~ ., feature_cols_data_rank3)
summary(ols)

# feature cols 2
ols <- lm(ranking_3 ~ ., train_data)
summary(ols)
pred <- predict.lm(ols, test_data[,head(names(test_data),-1)])
preds <- t(rbind(unname(floor(pred)), unname(test_data$ranking_3)))
colnames(preds) <- c("pred_rank", "actual_rank")
cm <- confusionMatrix(factor(preds[,'pred_rank']),factor(preds[,'actual_rank']))
cm

temp_df <- as.data.frame(cm$table)
colnames(temp_df) <- c("pred_rank", "actual_rank", "n")
plot_confusion_matrix(temp_df, target_col = "actual_rank",
                      prediction_col = "pred_rank",
                      counts_col = "n",
                      class_order=c("3","2","1"),
                      add_row_percentages = FALSE,
                      add_col_percentages = FALSE)


# feature cols 2 + album
ols <- lm(ranking_3 ~ ., feature_cols_album_data_rank3)
summary(ols)
```

## Clustering
### Clustereing with feature cols
```{r}
# silhouette plot
fviz_nbclust(feature_cols_data, kmeans, k.max=30,  method = "silhouette")

# K-means
model <- kmeans(feature_cols_data, iter.max=10, centers=3, nstart=25)
```

#### Max Ranking
```{r}
feature_cols_data_rank['kmeans'] <- model$cluster
run_lm_features(feature_cols_data_rank,color="kmeans")
# fviz_cluster(model, data = temp)
```

#### Ranking 3
```{r}
feature_cols_data_rank3['kmeans'] <- model$cluster
run_lm_features(feature_cols_data_rank3,color="kmeans", y="ranking_3")
# fviz_cluster(model, data = temp)
```

### Clustering with feature cols 2
```{r}
# silhouette plot
fviz_nbclust(feature_cols2_data, kmeans, k.max=10,  method = "silhouette")

# K-means
model <- kmeans(feature_cols2_data, iter.max=10, centers=2, nstart=25)
```

#### Max Ranking
```{r}
feature_cols2_data_rank['kmeans2'] <- model$cluster
run_lm_features(feature_cols2_data_rank,color="kmeans2", exclude_cols=exclude_cols)
# fviz_cluster(model, data = temp)
```

#### Ranking 3
```{r}
feature_cols2_data_rank3['kmeans2'] <- model$cluster
run_lm_features(feature_cols2_data_rank3,color="kmeans2", y="ranking_3")
fviz_cluster(model, data = feature_cols2_data)
```

### Clustering with feature cols 2 + album
```{r}
# silhouette plot
fviz_nbclust(feature_cols_album_data, kmeans, k.max=30,  method = "silhouette")

# K-means
model <- kmeans(feature_cols_album_data, iter.max=10, centers=2, nstart=25)
```

#### Max Ranking
```{r}
feature_cols_album_data_rank['kmeans_album'] <- model$cluster
run_lm_features(feature_cols_album_data_rank,color="kmeans_album", exclude_cols=exclude_cols)
# View(temp_full %>% count(kmeans, max_ranking) %>% count(kmeans))
# fviz_cluster(model, data = temp)
```

#### Ranking 3
```{r}
feature_cols_album_data_rank3['kmeans_album'] <- model$cluster
run_lm_features(feature_cols_album_data_rank3,color="kmeans_album", y="ranking_3")
# fviz_cluster(model, data = temp)
```

## Hirarchial Clustering
```{r}
d <- dist(feature_cols_data)
hclus_out <- hclust(d, "single")

plot(hclus_out, cex=0.9, hang=-1)
rect.hclust(hclus_out, k=4)

hcd <- as.dendrogram(hclus_out)
plot(hcd, xlim = c(1, 20), ylim = c(1,8))
```

```{r eval=FALSE, echo=FALSE}
fviz_dist(distance)
```


## DBSCAN
### DBSCAN feature cols
#### Max Ranking
```{r}
res <- dbscan(feature_cols2_data, eps = 2, minPts = 10)
feature_cols_data_rank["clus"] <- as.factor(res$cluster)
run_lm_features(feature_cols2_data_rank,color="clus", exclude_cols=exclude_cols)
```

#### Ranking 3
```{r}
res <- dbscan(feature_cols2_data, eps = 1.6, minPts = 10)
feature_cols2_data_rank3["clus"] <- as.factor(res$cluster)
run_lm_features(feature_cols2_data_rank3,color="clus", exclude_cols=exclude_cols, y="ranking_3")

temp <- sapply(seq(1,5,.1), function(x) length(table(dbscan(feature_cols2_data, eps = x, minPts = 10)$cluster)))
temp_df <- as.data.frame(cbind(seq(1,6,.1), temp))
colnames(temp_df) <- c("eps", "nClus")
ggplot(temp_df, aes(x=eps,y=nClus)) + geom_line() + geom_point()+
  ylab("Number of Clusters") + xlab("Eps Values") +
  ggtitle("Eps vs Number of Clusters")
ggsave("images/eps_clus.png")
```

### DBSCAN with feature cols 2
Didn't work out. Couldn't find eps. Cluster was k=2, too small.

### DBSCAN with feature cols 2 + album
Didn't work out. Couldn't find eps. Cluster was k=2, too small.

## Random Forest
### Max Ranking
```{r}
rf_features <- randomForest(max_ranking ~ .,feature_cols_data_rank,
                   importance=TRUE, proximity=TRUE)
rf_features
summary(rf_features)
round(importance(rf_features), 2)
# rf_features_mds <- cmdscale(1 - rf_features$proximity, eig=TRUE)
# op <- par(pty="s")
# pairs(cbind(feature_cols_data_rank[,-1], rf_features_mds$points), cex=0.6, gap=0,
#       col=as.numeric(feature_cols_data_rank$max_ranking),
#       main="Iris Data: Predictors and MDS of Proximity Based on RandomForest")
# par(op)

rf_features2 <- randomForest(max_ranking ~ .,feature_cols2_data_rank,
                   importance=TRUE, proximity=TRUE)
rf_features2
summary(rf_features2)
round(importance(rf_features2), 2)

rf_features_album <- randomForest(max_ranking ~ .,feature_cols_album_data_rank,
                   importance=TRUE, proximity=TRUE)
rf_features_album
summary(rf_features_album)
round(importance(rf_features_album), 2)
```
Link (%IncMSE IncNodePurity): https://stats.stackexchange.com/questions/162465/in-a-random-forest-is-larger-incmse-better-or-worse

### Ranking 3
```{r}
rf_features <- randomForesst(ranking_3 ~ .,feature_cols_data_rank3,
                   importance=TRUE, proximity=TRUE)
rf_features
summary(rf_features)
round(importance(rf_features), 2)
rf_features_mds <- cmdscale(1 - rf_features$proximity, eig=TRUE)
op <- par(pty="s")
pairs(cbind(feature_cols_data_rank3[,1:11], rf_features_mds$points), cex=0.6, gap=0,
      col=as.numeric(feature_cols_data_rank3$ranking_3),
      main="Iris Data: Predictors and MDS of Proximity Based on RandomForest")
par(op)

rf_features2 <- randomForest(ranking_3 ~ .,train_data,
                   importance=TRUE, proximity=TRUE)
rf_features2
summary(rf_features2)
round(importance(rf_features2), 2)


ols <- lm(ranking_3 ~ ., train_data)
summary(ols)
pred <- predict(rf_features2, test_data[,head(names(test_data),-1)])
preds <- t(rbind(unname(floor(pred)), unname(test_data$ranking_3)))
colnames(preds) <- c("pred_rank", "actual_rank")
cm <- confusionMatrix(factor(preds[,'pred_rank']),factor(preds[,'actual_rank']))
cm

temp_df <- as.data.frame(cm$table)
colnames(temp_df) <- c("pred_rank", "actual_rank", "n")
plot_confusion_matrix(temp_df, target_col = "actual_rank",
                      prediction_col = "pred_rank",
                      counts_col = "n",
                      class_order=c("3","2","1"),
                      add_row_percentages = FALSE,
                      add_col_percentages = FALSE)


rf_features_album <- randomForest(max_ranking ~ .,feature_cols_album_data_rank,
                   importance=TRUE, proximity=TRUE)
rf_features_album
summary(rf_features_album)
round(importance(rf_features_album), 2)
```